#!/usr/bin/env python3

#   __
# _/  |_ _______ _______ _______
# \   __\\_  __ \\_  __ \\_  __ \
#  |  |   |  | \/ |  | \/ |  | \/
#  |__|   |__|    |__|    |__|
# FIGMENTIZE: trrr

"""
Like tr, but it understands Unicode, by way of being a Python 3 program, and it
has built in a fairly large number of fancy looking unicode things.

The translation specs are passed through str.format, with access to a namespace
providing a number of alphabets, which are currently just latin letters with
font variations. This means you can use format specs like

`trrr '{upper}' '{lower}'` to lowercase some text, or

`trrr '{bold}{thin}' '{thin}{bold}'` to swap bold and thin letters.

If the length of the interpolated `to_spec` is a factor of that of `from_spec`,
`to_spec` will be replicated to restore parity. Otherwise, the specs should
generally have the same length. This little trick makes it easy to write  very
much surjective, non-injective mappings, like making everything smallcaps:

`trrr '{letters}' '{sc}'`, or

`trrr '{upper}{sc}' '{nm_u}' | trrr '{lower}' '{nm_l}'` to make everything
normal.

I have personally defined several aliases with "common" translations that I find
"useful".

You can also supply four further optional arguments. The first two are sets to
be subtracted from the specs, the second two are sets of characters for the
specs to be intersected with. This is probably useful for something, although
I've not quite figured out what it might be.

This script also acts as a module, which can be used to grab useful predefined
alphabets, or use some of the utility functions like `toupper()` and `islower()`
"""

# TODO: implement character ranger like A-Z, maybe.

import sys
import re

import smartparse as argparse

# Big start gained by scraping from here:
# https://www.compart.com/en/unicode/decomposition/%3Cfont%3E
# let s = ''; for (let e of document.querySelectorAll("p.text,div.text")) {s += e.innerHTML.trim()}; print(s)

# see also https://en.wikipedia.org/wiki/Mathematical_operators_and_symbols_in_Unicode#Mathematical_Alphanumeric_Symbols_block

# TODO: use some of these
# variant greek letters:
#     ğ›œğ›ğ›ğ›Ÿğ› ğ›¡
#     ğœ–ğœ—ğœ˜ğœ™ğœšğœ›
#     ğğ‘ğ’ğ“ğ”ğ•
#     ğŠğ‹ğŒğğğ
#     ğŸ„ğŸ…ğŸ†ğŸ‡ğŸˆğŸ‰
# misc maths: â„â„“â„¹â„¼â„½â„¾â„¿â…€â……â…†â…‡â…ˆâ…‰
# hebrew letters (eg aleph): ï¬ ï¬¡ï¬¢ï¬£ï¬¤ï¬¥ï¬¦ï¬§ï¬¨ï¬©
# dotless i, j: ğš¤ğš¥
# digammas: ğŸŠğŸ‹

# Some of these may well look a lot like normal ASCII letters, depending on what
# font you're using. However they are not, these are all Unicode letters, with
# explicit semantics about their typesetting, save for the "nm_" normal
# alphabets.
#
# See has_flag for a description of the naming convention here.
alphabets = {
    "nm_u": "ABCDEFGHIJKLMNOPQRSTUVWXYZ",
    "nm_l": "abcdefghijklmnopqrstuvwxyz",
    "nm_n": "0123456789",
    "nm_ub": "ğ€ğğ‚ğƒğ„ğ…ğ†ğ‡ğˆğ‰ğŠğ‹ğŒğğğğğ‘ğ’ğ“ğ”ğ•ğ–ğ—ğ˜ğ™",
    "nm_lb": "ğšğ›ğœğğğŸğ ğ¡ğ¢ğ£ğ¤ğ¥ğ¦ğ§ğ¨ğ©ğªğ«ğ¬ğ­ğ®ğ¯ğ°ğ±ğ²ğ³",
    "nm_nb": "ğŸğŸğŸğŸ‘ğŸ’ğŸ“ğŸ”ğŸ•ğŸ–ğŸ—",
    "nm_ui": "ğ´ğµğ¶ğ·ğ¸ğ¹ğºğ»ğ¼ğ½ğ¾ğ¿ğ‘€ğ‘ğ‘‚ğ‘ƒğ‘„ğ‘…ğ‘†ğ‘‡ğ‘ˆğ‘‰ğ‘Šğ‘‹ğ‘Œğ‘",
    "nm_li": "ğ‘ğ‘ğ‘ğ‘‘ğ‘’ğ‘“ğ‘”â„ğ‘–ğ‘—ğ‘˜ğ‘™ğ‘šğ‘›ğ‘œğ‘ğ‘ğ‘Ÿğ‘ ğ‘¡ğ‘¢ğ‘£ğ‘¤ğ‘¥ğ‘¦ğ‘§",
    "nm_ubi": "ğ‘¨ğ‘©ğ‘ªğ‘«ğ‘¬ğ‘­ğ‘®ğ‘¯ğ‘°ğ‘±ğ‘²ğ‘³ğ‘´ğ‘µğ‘¶ğ‘·ğ‘¸ğ‘¹ğ‘ºğ‘»ğ‘¼ğ‘½ğ‘¾ğ‘¿ğ’€ğ’",
    "nm_lbi": "ğ’‚ğ’ƒğ’„ğ’…ğ’†ğ’‡ğ’ˆğ’‰ğ’Šğ’‹ğ’Œğ’ğ’ğ’ğ’ğ’‘ğ’’ğ’“ğ’”ğ’•ğ’–ğ’—ğ’˜ğ’™ğ’šğ’›",
    "scr_u": "ğ’œâ„¬ğ’ğ’Ÿâ„°â„±ğ’¢â„‹â„ğ’¥ğ’¦â„’â„³ğ’©ğ’ªğ’«ğ’¬â„›ğ’®ğ’¯ğ’°ğ’±ğ’²ğ’³ğ’´ğ’µ",
    "scr_l": "ğ’¶ğ’·ğ’¸ğ’¹â„¯ğ’»â„Šğ’½ğ’¾ğ’¿ğ“€ğ“ğ“‚ğ“ƒâ„´ğ“…ğ“†ğ“‡ğ“ˆğ“‰ğ“Šğ“‹ğ“Œğ“ğ“ğ“",
    "scr_ub": "ğ“ğ“‘ğ“’ğ““ğ“”ğ“•ğ“–ğ“—ğ“˜ğ“™ğ“šğ“›ğ“œğ“ğ“ğ“Ÿğ“ ğ“¡ğ“¢ğ“£ğ“¤ğ“¥ğ“¦ğ“§ğ“¨ğ“©",
    "scr_lb": "ğ“ªğ“«ğ“¬ğ“­ğ“®ğ“¯ğ“°ğ“±ğ“²ğ“³ğ“´ğ“µğ“¶ğ“·ğ“¸ğ“¹ğ“ºğ“»ğ“¼ğ“½ğ“¾ğ“¿ğ”€ğ”ğ”‚ğ”ƒ",
    "frk_u": "ğ”„ğ”…â„­ğ”‡ğ”ˆğ”‰ğ”Šâ„Œâ„‘ğ”ğ”ğ”ğ”ğ”‘ğ”’ğ”“ğ””â„œğ”–ğ”—ğ”˜ğ”™ğ”šğ”›ğ”œâ„¨",
    "frk_l": "ğ”ğ”Ÿğ” ğ”¡ğ”¢ğ”£ğ”¤ğ”¥ğ”¦ğ”§ğ”¨ğ”©ğ”ªğ”«ğ”¬ğ”­ğ”®ğ”¯ğ”°ğ”±ğ”²ğ”³ğ”´ğ”µğ”¶ğ”·",
    "frk_ub": "ğ•¬ğ•­ğ•®ğ•¯ğ•°ğ•±ğ•²ğ•³ğ•´ğ•µğ•¶ğ•·ğ•¸ğ•¹ğ•ºğ•»ğ•¼ğ•½ğ•¾ğ•¿ğ–€ğ–ğ–‚ğ–ƒğ–„ğ–…",
    "frk_lb": "ğ–†ğ–‡ğ–ˆğ–‰ğ–Šğ–‹ğ–Œğ–ğ–ğ–ğ–ğ–‘ğ–’ğ–“ğ–”ğ–•ğ––ğ–—ğ–˜ğ–™ğ–šğ–›ğ–œğ–ğ–ğ–Ÿ",
    "sns_u": "ğ– ğ–¡ğ–¢ğ–£ğ–¤ğ–¥ğ–¦ğ–§ğ–¨ğ–©ğ–ªğ–«ğ–¬ğ–­ğ–®ğ–¯ğ–°ğ–±ğ–²ğ–³ğ–´ğ–µğ–¶ğ–·ğ–¸ğ–¹",
    "sns_l": "ğ–ºğ–»ğ–¼ğ–½ğ–¾ğ–¿ğ—€ğ—ğ—‚ğ—ƒğ—„ğ—…ğ—†ğ—‡ğ—ˆğ—‰ğ—Šğ—‹ğ—Œğ—ğ—ğ—ğ—ğ—‘ğ—’ğ—“",
    "sns_n": "ğŸ¢ğŸ£ğŸ¤ğŸ¥ğŸ¦ğŸ§ğŸ¨ğŸ©ğŸªğŸ«",
    "sns_ub": "ğ—”ğ—•ğ—–ğ——ğ—˜ğ—™ğ—šğ—›ğ—œğ—ğ—ğ—Ÿğ— ğ—¡ğ—¢ğ—£ğ—¤ğ—¥ğ—¦ğ—§ğ—¨ğ—©ğ—ªğ—«ğ—¬ğ—­",
    "sns_lb": "ğ—®ğ—¯ğ—°ğ—±ğ—²ğ—³ğ—´ğ—µğ—¶ğ—·ğ—¸ğ—¹ğ—ºğ—»ğ—¼ğ—½ğ—¾ğ—¿ğ˜€ğ˜ğ˜‚ğ˜ƒğ˜„ğ˜…ğ˜†ğ˜‡",
    "sns_nb": "ğŸ¬ğŸ­ğŸ®ğŸ¯ğŸ°ğŸ±ğŸ²ğŸ³ğŸ´ğŸµ",
    "sns_ui": "ğ˜ˆğ˜‰ğ˜Šğ˜‹ğ˜Œğ˜ğ˜ğ˜ğ˜ğ˜‘ğ˜’ğ˜“ğ˜”ğ˜•ğ˜–ğ˜—ğ˜˜ğ˜™ğ˜šğ˜›ğ˜œğ˜ğ˜ğ˜Ÿğ˜ ğ˜¡",
    "sns_li": "ğ˜¢ğ˜£ğ˜¤ğ˜¥ğ˜¦ğ˜§ğ˜¨ğ˜©ğ˜ªğ˜«ğ˜¬ğ˜­ğ˜®ğ˜¯ğ˜°ğ˜±ğ˜²ğ˜³ğ˜´ğ˜µğ˜¶ğ˜·ğ˜¸ğ˜¹ğ˜ºğ˜»",
    "sns_ubi": "ğ˜¼ğ˜½ğ˜¾ğ˜¿ğ™€ğ™ğ™‚ğ™ƒğ™„ğ™…ğ™†ğ™‡ğ™ˆğ™‰ğ™Šğ™‹ğ™Œğ™ğ™ğ™ğ™ğ™‘ğ™’ğ™“ğ™”ğ™•",
    "sns_lbi": "ğ™–ğ™—ğ™˜ğ™™ğ™šğ™›ğ™œğ™ğ™ğ™Ÿğ™ ğ™¡ğ™¢ğ™£ğ™¤ğ™¥ğ™¦ğ™§ğ™¨ğ™©ğ™ªğ™«ğ™¬ğ™­ğ™®ğ™¯",
    "tt_u": "ğ™°ğ™±ğ™²ğ™³ğ™´ğ™µğ™¶ğ™·ğ™¸ğ™¹ğ™ºğ™»ğ™¼ğ™½ğ™¾ğ™¿ğš€ğšğš‚ğšƒğš„ğš…ğš†ğš‡ğšˆğš‰",
    "tt_l": "ğšŠğš‹ğšŒğšğšğšğšğš‘ğš’ğš“ğš”ğš•ğš–ğš—ğš˜ğš™ğššğš›ğšœğšğšğšŸğš ğš¡ğš¢ğš£",
    "tt_n": "ğŸ¶ğŸ·ğŸ¸ğŸ¹ğŸºğŸ»ğŸ¼ğŸ½ğŸ¾ğŸ¿",
    "bb_u": "ğ”¸ğ”¹â„‚ğ”»ğ”¼ğ”½ğ”¾â„ğ•€ğ•ğ•‚ğ•ƒğ•„â„•ğ•†â„™â„šâ„ğ•Šğ•‹ğ•Œğ•ğ•ğ•ğ•â„¤",
    "bb_l": "ğ•’ğ•“ğ•”ğ••ğ•–ğ•—ğ•˜ğ•™ğ•šğ•›ğ•œğ•ğ•ğ•Ÿğ• ğ•¡ğ•¢ğ•£ğ•¤ğ•¥ğ•¦ğ•§ğ•¨ğ•©ğ•ªğ•«",
    "bb_n": "ğŸ˜ğŸ™ğŸšğŸ›ğŸœğŸğŸğŸŸğŸ ğŸ¡",
    # TODO: x is faked here. Apparently smallcaps X doesn't even exist,
    #       according to Wikipedia.
    "sc": "á´€Ê™á´„á´…á´‡êœ°É¢ÊœÉªá´Šá´‹ÊŸá´É´á´á´˜ê¯Ê€êœ±á´›á´œá´ á´¡xÊá´¢",
    # https://jkirchartz.com/demos/fake_russian_generator.html
    "cyrillicfake": "Ğ”Ğ‘ÒªDÔÒ’GÒ¤Ğ‡JÒœLÔ Ğ™Ğ¤PQĞ¯SĞ“Ğ¦VĞ¨Ó¼Ò°Z",
    "nm_ug": "Î‘Î’Î“Î”Î•Î–Î—Î˜Î™ÎšÎ›ÎœÎÎÎŸÎ Î¡Ï´Î£Î¤Î¥Î¦Î§Î¨Î©âˆ‡",
    "nm_lg": "Î±Î²Î³Î´ÎµÎ¶Î·Î¸Î¹ÎºÎ»Î¼Î½Î¾Î¿Ï€ÏÏ‚ÏƒÏ„Ï…Ï†Ï‡ÏˆÏ‰âˆ‚",
    # ordering to be considered unstable. It's probably actually pretty
    # insensitive to jam it all in in this way to make 26 letters, but I can't
    # think of a better way to go about this
    "nm_ubg": "ğš¨ğš©ğšªğš«ğš¬ğš­ğš®ğš¯ğš°ğš±ğš²ğš³ğš´ğšµğš¶ğš·ğš¸ğš¹ğšºğš»ğš¼ğš½ğš¾ğš¿ğ›€ğ›",
    "nm_lbg": "ğ›‚ğ›ƒğ›„ğ›…ğ›†ğ›‡ğ›ˆğ›‰ğ›Šğ›‹ğ›Œğ›ğ›ğ›ğ›ğ›‘ğ›’ğ›“ğ›”ğ›•ğ›–ğ›—ğ›˜ğ›™ğ›šğ››",
    "nm_uig": "ğ›¢ğ›£ğ›¤ğ›¥ğ›¦ğ›§ğ›¨ğ›©ğ›ªğ›«ğ›¬ğ›­ğ›®ğ›¯ğ›°ğ›±ğ›²ğ›³ğ›´ğ›µğ›¶ğ›·ğ›¸ğ›¹ğ›ºğ›»",
    "nm_lig": "ğ›¼ğ›½ğ›¾ğ›¿ğœ€ğœğœ‚ğœƒğœ„ğœ…ğœ†ğœ‡ğœˆğœ‰ğœŠğœ‹ğœŒğœğœğœğœğœ‘ğœ’ğœ“ğœ”ğœ•",
    "nm_ubig": "ğœœğœğœğœŸğœ ğœ¡ğœ¢ğœ£ğœ¤ğœ¥ğœ¦ğœ§ğœ¨ğœ©ğœªğœ«ğœ¬ğœ­ğœ®ğœ¯ğœ°ğœ±ğœ²ğœ³ğœ´ğœµ",
    "nm_lbig": "ğœ¶ğœ·ğœ¸ğœ¹ğœºğœ»ğœ¼ğœ½ğœ¾ğœ¿ğ€ğğ‚ğƒğ„ğ…ğ†ğ‡ğˆğ‰ğŠğ‹ğŒğğğ",
    # annoyingly, there doesn't seem to exist a regular set of greek sans-serif
    # symbols, so I'm reusing the normal Roman ones in order not to break large
    # conversions. Similar for sans-serif italics.
    "sns_ug": "Î‘Î’Î“Î”Î•Î–Î—Î˜Î™ÎšÎ›ÎœÎÎÎŸÎ Î¡Ï´Î£Î¤Î¥Î¦Î§Î¨Î©âˆ‡",
    "sns_lg": "Î±Î²Î³Î´ÎµÎ¶Î·Î¸Î¹ÎºÎ»Î¼Î½Î¾Î¿Ï€ÏÏ‚ÏƒÏ„Ï…Ï†Ï‡ÏˆÏ‰âˆ‚",
    "sns_ubg": "ğ–ğ—ğ˜ğ™ğšğ›ğœğğğŸğ ğ¡ğ¢ğ£ğ¤ğ¥ğ¦ğ§ğ¨ğ©ğªğ«ğ¬ğ­ğ®ğ¯",
    "sns_lbg": "ğ°ğ±ğ²ğ³ğ´ğµğ¶ğ·ğ¸ğ¹ğºğ»ğ¼ğ½ğ¾ğ¿ğ€ğğ‚ğƒğ„ğ…ğ†ğ‡ğˆğ‰",
    "sns_uig": "ğ›¢ğ›£ğ›¤ğ›¥ğ›¦ğ›§ğ›¨ğ›©ğ›ªğ›«ğ›¬ğ›­ğ›®ğ›¯ğ›°ğ›±ğ›²ğ›³ğ›´ğ›µğ›¶ğ›·ğ›¸ğ›¹ğ›ºğ›»",
    "sns_lig": "ğ›¼ğ›½ğ›¾ğ›¿ğœ€ğœğœ‚ğœƒğœ„ğœ…ğœ†ğœ‡ğœˆğœ‰ğœŠğœ‹ğœŒğœğœğœğœğœ‘ğœ’ğœ“ğœ”ğœ•",
    "sns_ubig": "ğğ‘ğ’ğ“ğ”ğ•ğ–ğ—ğ˜ğ™ğšğ›ğœğğğŸğ ğ¡ğ¢ğ£ğ¤ğ¥ğ¦ğ§ğ¨ğ©",
    "sns_lbig": "ğªğ«ğ¬ğ­ğ®ğ¯ğ°ğ±ğ²ğ³ğ´ğµğ¶ğ·ğ¸ğ¹ğºğ»ğ¼ğ½ğ¾ğ¿ğŸ€ğŸğŸ‚ğŸƒ"
    }

auxiliary = {}

def has_flag(alph, flag):
    """
    Check if some alphabet key contains a flag, as per the convention of a name
    followed by an optional (underscore followed by single-letter flags).
    """
    return re.match(r"^[a-z]*_[a-z]*{}[a-z]*$".format(flag), alph)

def sub_flag(alph, flag, repl):
    """
    Replace a flag with another as per the above convention.
    """
    name, flags = alph.split("_")
    return "{}_{}".format(name, flags.replace(flag, repl))

def gen_flag_pair(flag1, flag2, alphabets):
    """
    Find all alphabets containing flag1, and return two lists, one of all
    alphabets with flag1, and another of all these alphabets with flag1 replaced
    by flag2. flag2 may be the empty string.
    """
    list1, list2 = [], []
    for alph in alphabets:
        if has_flag(alph, flag1):
            list1.append(alph)
            list2.append(sub_flag(alph, flag1, flag2))
    return ("".join(alphabets[a] for a in list1),
            "".join(alphabets[a] for a in list2))

# all alphabets for which it makes sense to convert between case
auxiliary["upper"], auxiliary["lower"] = gen_flag_pair("u", "l", alphabets)

# all alphabets for which it makes sense to convert between weight
auxiliary["bold"], auxiliary["thin"] = gen_flag_pair("b", "", alphabets)

# all alphabets for which it makes sense to convert to/from italic
auxiliary["italic"], auxiliary["straight"] = gen_flag_pair("i", "", alphabets)

# all alphabets for which it makes sense to convert to/from greek
auxiliary["greek"], auxiliary["notgreek"] = gen_flag_pair("g", "", alphabets)

# all letters and all numbers
# The blacklisting approach is a little unstable, I know, but it's s o m u c h
# more concise
auxiliary["letters"] = "".join(alphabets[a] for a in alphabets
        if not (has_flag(a, "n") or has_flag(a, "g") or a == "cyrillicfake"))
auxiliary["numbers"] = "".join(alphabets[a] for a in alphabets
        if has_flag(a, "n"))

def summarise_alphabets(alphabets):
    """
    Produce a summary of alphabets
    """
    # determine longest key
    w = max(map(len, alphabets))
    for k, alph in alphabets.items():
        print("    {:{w}}: {}".format(k, alph, w=w))

class ListAction(argparse._HelpAction):
    """
    Action that must override any other parsing to produce a list and exit,
    which is actually very similar functionality to -h, so we reappropriate
    HelpAction.
    """
    def __call__(self, parser, namespace, values, option_string=None):
        print("Base alphabets:")
        summarise_alphabets(alphabets)
        print("Composed alphabets:")
        summarise_alphabets(auxiliary)
        sys.exit()

def get_args():
    """
    Parse argv
    """
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("-l", "--list", action=ListAction,
            help="""Do not translate, instead produce a list of available
                    alphabets.""")
    parser.add_argument("from_spec",
            help="Spec for the set of characters to be translated")
    parser.add_argument("to_spec",
            help="Spec for the set of characters to be translated to")
    parser.add_argument("from_spec_sub", nargs="?", default="",
            help="Spec to subtract from from_spec")
    parser.add_argument("to_spec_sub", nargs="?", default="",
            help="Spec to subtract from to_spec")
    parser.add_argument("from_spec_inter", nargs="?", default="",
            help="Spec to intersect from_spec with")
    parser.add_argument("to_spec_inter", nargs="?", default="",
            help="Spec to intersect to_spec with")
    parser.add_argument("-u", "--unbuffered", action="store_true",
            help="""Flush stdout after each line, Useful in pipes if you want
                    immediate output""")
    args = parser.parse_args()
    if not args.to_spec or not args.from_spec:
        parser.error("from_spec and to_spec should be nonempty.")
    return args

upper_trans = str.maketrans(auxiliary["lower"], auxiliary["upper"])
lower_trans = str.maketrans(auxiliary["upper"], auxiliary["lower"])

def toupper(s):
    """
    Even more unicode-supporting uppercasing function.

    It only acts as a humble wrapper to str.upper(), moreover giving str.upper
    precedence. This is because str.upper is already basically quite good at
    multilingual casing, and I only care about the weird typesetting-y
    codepoints for entirely nefarious purposes.
    """
    return s.translate(upper_trans).upper()

def tolower(s):
    """
    Even more unicode-supporting lowercasing function. See above
    """
    return s.translate(lower_trans).lower()

def isupper(s):
    """
    Unicode-supporting uppercase detection function, similar to toupper(). Wraps
    _isupper which acts on single characters.

    Tries to short-circuit with the presumably fast Python primitive
    str.isupper.
    """
    return s.isupper() or all(_isupper(c) for c in s)

def islower(s):
    """
    Similar to isupper() above, with one crucial difference
    """
    return s.islower() or all(_islower(c) for c in s)

def _isupper(c):
    """
    Determine if a single character is uppercase
    """
    return c.isupper() or c in upper_trans

def _islower(c):
    """
    Determine if a single character is lowercase
    """
    return c.isupper() or c in upper_trans

class YesMan:
    """
    Dummy class that replies yes to any membership queries, used for the
    default type of intersection.
    """
    def __contains__(self, item):
        return True

def interpret_spec(spec, spec_sub, spec_inter, alphabets, auxiliary):
    """
    Build a proper character set from a spec, it's subtraction and its
    intersection.
    """
    sub_set = set(spec_sub.format(**alphabets, **auxiliary))
    inter_set = set(spec_inter.format(**alphabets, **auxiliary))
    if not inter_set:
        inter_set = YesMan()
    return "".join(c for c in spec.format(**alphabets, **auxiliary)
            if c not in sub_set and c in inter_set)

def trrr(from_spec, to_spec, from_spec_sub="", to_spec_sub="",
         from_spec_inter="", to_spec_inter="", in_file=sys.stdin,
         out_file=sys.stdout, err_file=sys.stderr, alphabets=alphabets,
         auxiliary=auxiliary, unbuffered=False):
    """
    Perform the actual translation, interpreting the specs using the alphabets.
    """
    from_full = interpret_spec(from_spec, from_spec_sub, from_spec_inter,
                               alphabets, auxiliary)
    to_full = interpret_spec(to_spec, to_spec_sub, to_spec_inter,
                             alphabets, auxiliary)
    if len(from_full) % len(to_full) == 0:
        to_full = to_full * (len(from_full) // len(to_full))
    else:
        print("from_spec should resolve to a length that is a "
              "multiple of that of to_spec",
                file=err_file)
        sys.exit(1)
    trans = str.maketrans(from_full, to_full)
    for line in in_file:
        out_file.write(line.translate(trans))
        if unbuffered:
            out_file.flush()

if __name__ == "__main__":
    args = get_args()
    trrr(**vars(args))
